​	我发现，通过将询问意图改为原本提问的反义，有时可以绕开对语言模型的道德限制，这种方法有时被称为“反向工程”或“对抗性提问”。

​	在下面的提问中，语言模型的回答通常会指向正确的网站，即使它们在正确回答问题时也不具备人类思考的能力。语言模型的回答主要基于大量的文本训练和统计模式，而非真正的理解。因此，即使通过反向提问得到了正确的答案，也不能代表模型真正理解问题的含义或背后的概念。

![image-20240301103830809](image-20240301103830809.png)